{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000027050C1E240>\n",
      "train_data size 6680\n",
      "test_data size 836\n",
      "valid_data size 835\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "normalize = transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocess_train = transforms.Compose([transforms.RandomResizedCrop(256),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    normalize])\n",
    "\n",
    "preprocess_test = transforms.Compose([transforms.RandomResizedCrop(256),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    normalize])\n",
    "\n",
    "train_data = datasets.ImageFolder(root='dogImages/train',transform=preprocess_train)\n",
    "test_data = datasets.ImageFolder(root='dogImages/test',transform=preprocess_test)\n",
    "valid_data = datasets.ImageFolder(root='dogImages/valid',transform=preprocess_test)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset=train_data,batch_size=32,shuffle=True,num_workers=1)\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset=test_data,batch_size=32,shuffle=True,num_workers=1)\n",
    "valid_data_loader = torch.utils.data.DataLoader(dataset=valid_data,batch_size=32,shuffle=True,num_workers=1)\n",
    "\n",
    "loaders_scratch = {\n",
    "        \"train\" : train_data_loader,\n",
    "        \"test\" : test_data_loader,\n",
    "        \"valid\" : valid_data_loader,\n",
    "}\n",
    "\n",
    "#printing and check the loaded data\n",
    "print(train_data_loader)\n",
    "print(\"train_data size\", len(train_data))\n",
    "print(\"test_data size\", len(test_data))\n",
    "print(\"valid_data size\", len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        self.conv1=nn.Conv2d(3,16,4,stride=1)\n",
    "        self.conv2=nn.Conv2d(16,32,4,stride=1)\n",
    "        self.conv3=nn.Conv2d(32,64,4,stride=1)\n",
    "        self.conv4=nn.Conv2d(64,128,4,stride=1)\n",
    "        self.conv5=nn.Conv2d(128,256,4,stride=1)\n",
    "        self.pool=nn.MaxPool2d(2,2)\n",
    "        self.fc1=nn.Linear(256*5*5,1024)\n",
    "        self.fc2=nn.Linear(1024,512)\n",
    "        self.fc3=nn.Linear(512,133)\n",
    "        self.dropout=nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ## Define forward behavior\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.pool(F.relu(self.conv3(x)))\n",
    "        x=self.pool(F.relu(self.conv4(x)))\n",
    "        x=self.pool(F.relu(self.conv5(x)))\n",
    "        x=x.view(-1,256*5*5)\n",
    "        x=self.dropout(x)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.dropout(x)\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.dropout(x)\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# instantiate the CNN\n",
    "model_scratch = Net()\n",
    "    \n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    model_scratch.cuda()\n",
    "\n",
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "### TODO: select optimizer\n",
    "optimizer_scratch = optim.SGD(model_scratch.parameters(), lr=0.025)\n",
    "#empty the cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 138, in __getitem__\n    sample = self.loader(path)\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 174, in default_loader\n    return pil_loader(path)\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 157, in pil_loader\n    return img.convert('RGB')\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\PIL\\Image.py\", line 873, in convert\n    self.load()\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\PIL\\ImageFile.py\", line 247, in load\n    \"(%d bytes not processed)\" % len(b)\nOSError: image file is truncated (150 bytes not processed)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a11c8f5b7f59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m model_scratch = train(35, loaders_scratch, model_scratch, optimizer_scratch, \n\u001b[1;32m---> 68\u001b[1;33m                                     criterion_scratch, use_cuda, 'model_scratch.pt')\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[1;31m# load the model that got the best validation accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0mmodel_scratch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model_scratch.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a11c8f5b7f59>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;31m###################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[1;31m# move to GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 881\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    882\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m: Caught OSError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 178, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 138, in __getitem__\n    sample = self.loader(path)\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 174, in default_loader\n    return pil_loader(path)\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\torchvision\\datasets\\folder.py\", line 157, in pil_loader\n    return img.convert('RGB')\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\PIL\\Image.py\", line 873, in convert\n    self.load()\n  File \"C:\\Anaconda3\\envs\\DLND\\lib\\site-packages\\PIL\\ImageFile.py\", line 247, in load\n    \"(%d bytes not processed)\" % len(b)\nOSError: image file is truncated (150 bytes not processed)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "        \"\"\"returns trained model\"\"\"\n",
    "        # initialize tracker for minimum validation loss\n",
    "        valid_loss_min = np.Inf \n",
    "        for epoch in range(1, n_epochs+1):\n",
    "            # initialize variables to monitor training and validation loss\n",
    "            train_loss = 0.0\n",
    "            valid_loss = 0.0\n",
    "            ###################\n",
    "            # train the model #\n",
    "            ###################\n",
    "            model.train()\n",
    "            for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "                # move to GPU\n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                ## find the loss and update the model parameters accordingly\n",
    "                ## record the average training loss, using something like\n",
    "                # clear the gradients of all optimized variables\n",
    "                optimizer.zero_grad()\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model.forward(data)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, target)\n",
    "                # backward pass: compute gradient of the loss with respect to model parameters\n",
    "                loss.backward()\n",
    "                # perform a single optimization step (parameter update)\n",
    "                optimizer.step()\n",
    "                # update training loss\n",
    "                train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            ######################    \n",
    "            # validate the model #\n",
    "            ###################### \n",
    "            model.eval()\n",
    "            for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "                # move to GPU\n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "                ## update the average validation loss\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = model.forward(data)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, target)\n",
    "                # update validation loss\n",
    "                valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            # print training/validation statistics \n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                train_loss,\n",
    "                valid_loss\n",
    "                ))\n",
    "            ## TODO: save the model if validation loss has decreased\n",
    "            # Save model if validation loss has decreased since last min\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                valid_loss_min = valid_loss\n",
    "        # return trained model\n",
    "        return model\n",
    "    \n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    \n",
    "    # train the model\n",
    "model_scratch = train(35, loaders_scratch, model_scratch, optimizer_scratch, \n",
    "                                    criterion_scratch, use_cuda, 'model_scratch.pt')\n",
    "    # load the model that got the best validation accuracy\n",
    "model_scratch.load_state_dict(torch.load('model_scratch.pt'))\n",
    "#Here is my outputs from training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "            100. * correct / total, correct, total))\n",
    "# call test function    \n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('DLND': conda)",
   "language": "python",
   "name": "python361064bitdlndconda4430f9d44308475bbecac6eda3a772b0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
